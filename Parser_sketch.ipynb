{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. когда я открываю файл я выхожу из контекстного менеджера и есть вероятность зарыть его без сохранения (а значит он может или недозаписаться или вообще удалить данные)\n",
    "0. продумать проверку лога браузера и лога с билетами (сейчас это не оптимально сделано)\n",
    "\n",
    "\n",
    "\n",
    "Из KLO не строит до пекина\n",
    "\n",
    "0. Глянуть через фукок\n",
    "\n",
    "0.продумать запись полетов к api что их нет (потому что если через браузер мы записал, чтобыл запрос, но билетов по факту нет, то к обращаясь к api мы получаем ошибку)\n",
    "0. генерация из цепочек более сложных перелетов, например из ('KWE', 'PVG'), ('PVG', 'MOW') => ('KWE', 'MOW')\n",
    "0. сделать стопер, что если цепочка явно дорогая (пока не понятно как это определять), то выкидывать ее сразу из анализу\n",
    "0. для того чтобы не калбасить все даты, продумать, как отлет или прилет передевать параметром, чтобы не по всем дням проходить\n",
    "0. в парсер добавить перебор длинных маршрутов\n",
    "0. очистка ticket base после полной загрузки (удаление дублей)\n",
    "0. умный перебор: смотреть если перелет из точки А в точку B и в точку C (если нет из B в C то А в B не нужно)\n",
    "\n",
    "\n",
    "0. когда точек отправления 2 и более сделеать\n",
    "0. умная фильтрация по столбцам (все одинаковые фичи шли подряд)\n",
    "0. составление маршрутов когда 2 и более точек\n",
    "0. при фильтрации добавить duration (когда сравниваю две даты)\n",
    "0. реализовать систему весов для сортировки\n",
    "0. киллер фича, это учет часовых поясов аэропортов, даты начала рейса, продолжительности для высчитывания во сколько ты прилетаешь\n",
    "0. продумать как json дозаписывать\n",
    "0. сделать нормальную функцию группировки\n",
    "0. для умной генерации маршрутов нужно навесить кучу ограничений, например, такого не должно быть:\n",
    "\n",
    "[('KWE', 'TYN'), ('TYN', 'KWE'), ('KWE', 'PVG'), ('PVG', 'MOW')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://support.travelpayouts.com/hc/ru/categories/200358578-API-%D0%B8-%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5\n",
    "# https://support.travelpayouts.com/hc/ru/articles/203956163-Aviasales-API-%D0%B4%D0%BE%D1%81%D1%82%D1%83%D0%BF%D0%B0-%D0%BA-%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D0%BC-%D0%B4%D0%BB%D1%8F-%D1%83%D1%87%D0%B0%D1%81%D1%82%D0%BD%D0%B8%D0%BA%D0%BE%D0%B2-%D0%BF%D0%B0%D1%80%D1%82%D0%BD%D0%B5%D1%80%D1%81%D0%BA%D0%BE%D0%B9-%D0%BF%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D1%8B#15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_TOKEN = 'b8848ff67e92768d2d1977862372d796'\n",
    "\n",
    "origin = ['KWE']#'KWE'\n",
    "final_destination = ['TSE']#['LED', 'MOW', 'TLL', 'HEL'] #'LED' 'KLO'\n",
    "range_date = ['2020-01-12', '2020-01-15']\n",
    "#number_place = 0\n",
    "\n",
    "time_sleep = 1\n",
    "date_start, date_end = range_date[0], range_date[1]\n",
    "\n",
    "url = 'http://api.travelpayouts.com/v2/prices/month-matrix'\n",
    "\n",
    "# group = ['DME', 'SVO', 'VKO', 'ZIA']\n",
    "\n",
    "wishful_point = [] #'KLO'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import codecs\n",
    "import os\n",
    "\n",
    "from itertools import product\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "\n",
    "add_zero = lambda x: '0' + str(x) if len(str(x)) < 2 else str(x)\n",
    "# Используйте тут ваш путь к chromedriver!\n",
    "chromedriver_path = 'chromedriver.exe'\n",
    "driver = webdriver.Chrome(executable_path=chromedriver_path) # Этой командой открывается окно Chrome\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = codecs.open('airports.json', encoding='utf-8', mode='r')\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = list(map(lambda x: x['city_code'], data))\n",
    "points = list(map(lambda x: x['code'], data))\n",
    "cities_points = {city:[] for city in cities}\n",
    "list(map(lambda x, y: cities_points[x].append(y) , cities, points))\n",
    "cities_points = {k: v for k, v in cities_points.items() if len(v) > 1}\n",
    "cities_points = list(cities_points.keys())\n",
    "\n",
    "mapper =  dict(zip(points, cities))\n",
    "mapper = {k: v for k, v in mapper.items() if v in cities_points}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_routes = 'http://api.travelpayouts.com/data/routes.json'\n",
    "routes = json.loads(requests.get(url_routes).text)\n",
    "route_chain = list(map(lambda x: [x['departure_airport_iata'], x['arrival_airport_iata']], routes))\n",
    "\n",
    "def group_airport(route, mapper):\n",
    "    if route[1] in mapper.keys(): route[1] = mapper[route[1]]\n",
    "    if route[0] in mapper.keys(): route[0] = mapper[route[0]]\n",
    "    return route\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_chain = list(map(lambda x: group_airport(x, mapper), route_chain))\n",
    "route_chain = list(set(map(lambda x: tuple(x), route_chain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone = ['Asia/Aden',\n",
    " 'Asia/Almaty',\n",
    " 'Asia/Amman',\n",
    " 'Asia/Anadyr',\n",
    " 'Asia/Aqtau',\n",
    " 'Asia/Aqtobe',\n",
    " 'Asia/Ashgabat',\n",
    " 'Asia/Baghdad',\n",
    " 'Asia/Bahrain',\n",
    " 'Asia/Baku',\n",
    " 'Asia/Bangkok',\n",
    " 'Asia/Beirut',\n",
    " 'Asia/Bishkek',\n",
    " 'Asia/Brunei',\n",
    " 'Asia/Chita',\n",
    " 'Asia/Choibalsan',\n",
    " 'Asia/Chongqing',\n",
    " 'Asia/Colombo',\n",
    " 'Asia/Damascus',\n",
    " 'Asia/Dhaka',\n",
    " 'Asia/Dili',\n",
    " 'Asia/Dubai',\n",
    " 'Asia/Dushanbe',\n",
    " 'Asia/Gaza',\n",
    " 'Asia/Ho_Chi_Minh',\n",
    " 'Asia/Hong_Kong',\n",
    " 'Asia/Hovd',\n",
    " 'Asia/Irkutsk',\n",
    " 'Asia/Istanbul',\n",
    " 'Asia/Jakarta',\n",
    " 'Asia/Jayapura',\n",
    " 'Asia/Jerusalem',\n",
    " 'Asia/Kabul',\n",
    " 'Asia/Kamchatka',\n",
    " 'Asia/Karachi',\n",
    " 'Asia/Kathmandu',\n",
    " 'Asia/Kolkata',\n",
    " 'Asia/Krasnoyarsk',\n",
    " 'Asia/Kuala_Lumpur',\n",
    " 'Asia/Kuching',\n",
    " 'Asia/Kuwait',\n",
    " 'Asia/Macau',\n",
    " 'Asia/Magadan',\n",
    " 'Asia/Makassar',\n",
    " 'Asia/Manila',\n",
    " 'Asia/Muscat',\n",
    " 'Asia/Nicosia',\n",
    " 'Asia/Novokuznetsk',\n",
    " 'Asia/Novosibirsk',\n",
    " 'Asia/Omsk',\n",
    " 'Asia/Oral',\n",
    " 'Asia/Phnom_Penh',\n",
    " 'Asia/Pontianak',\n",
    " 'Asia/Pyongyang',\n",
    " 'Asia/Qatar',\n",
    " 'Asia/Qyzylorda',\n",
    " 'Asia/Rangoon',\n",
    " 'Asia/Riyadh',\n",
    " 'Asia/Sakhalin',\n",
    " 'Asia/Samarkand',\n",
    " 'Asia/Seoul',\n",
    " 'Asia/Shanghai',\n",
    " 'Asia/Singapore',\n",
    " 'Asia/Srednekolymsk',\n",
    " 'Asia/Taipei',\n",
    " 'Asia/Tashkent',\n",
    " 'Asia/Tbilisi',\n",
    " 'Asia/Tehran',\n",
    " 'Asia/Thimphu',\n",
    " 'Asia/Tokyo',\n",
    " 'Asia/Ulaanbaatar',\n",
    " 'Asia/Ust-Nera',\n",
    " 'Asia/Vientiane',\n",
    " 'Asia/Vladivostok',\n",
    " 'Asia/Yakutsk',\n",
    " 'Asia/Yekaterinburg',\n",
    " 'Asia/Yerevan',\n",
    "'Indian/Antananarivo',\n",
    " 'Indian/Christmas',\n",
    " 'Indian/Cocos',\n",
    " 'Indian/Comoro',\n",
    " 'Indian/Mahe',\n",
    " 'Indian/Maldives',\n",
    " 'Indian/Mauritius',\n",
    " 'Indian/Mayotte',\n",
    " 'Indian/Reunion',\n",
    " 'Pacific/Apia',\n",
    " 'Pacific/Auckland',\n",
    " 'Pacific/Chatham',\n",
    " 'Pacific/Chuuk',\n",
    " 'Pacific/Easter',\n",
    " 'Pacific/Efate',\n",
    " 'Pacific/Enderbury',\n",
    " 'Pacific/Fiji',\n",
    " 'Pacific/Funafuti',\n",
    " 'Pacific/Galapagos',\n",
    " 'Pacific/Gambier',\n",
    " 'Pacific/Guadalcanal',\n",
    " 'Pacific/Guam',\n",
    " 'Pacific/Honolulu',\n",
    " 'Pacific/Johnston',\n",
    " 'Pacific/Kiritimati',\n",
    " 'Pacific/Kosrae',\n",
    " 'Pacific/Kwajalein',\n",
    " 'Pacific/Majuro',\n",
    " 'Pacific/Marquesas',\n",
    " 'Pacific/Midway',\n",
    " 'Pacific/Nauru',\n",
    " 'Pacific/Niue',\n",
    " 'Pacific/Norfolk',\n",
    " 'Pacific/Noumea',\n",
    " 'Pacific/Pago_Pago',\n",
    " 'Pacific/Palau',\n",
    " 'Pacific/Pohnpei',\n",
    " 'Pacific/Port_Moresby',\n",
    " 'Pacific/Rarotonga',\n",
    " 'Pacific/Saipan',\n",
    " 'Pacific/Tahiti',\n",
    " 'Pacific/Tarawa',\n",
    " 'Pacific/Tongatapu',\n",
    " 'Pacific/Wake',\n",
    " 'Pacific/Wallis']\n",
    "\n",
    "directions = list(filter(lambda x: x['time_zone'] in zone, data))\n",
    "#directions = list(filter(lambda x: x['country_code'] in ['CN'], directions))\n",
    "directions = list(map(lambda x: x['city_code'], directions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_chain(arrivals, route_chain, final_destination, final = False):\n",
    "    if final:\n",
    "        next_chain = filter(lambda x: (x[0] in arrivals) & (x[1] in final_destination), route_chain)\n",
    "    else:\n",
    "        next_chain = filter(lambda x: x[0] in arrivals, route_chain)\n",
    "    return next_chain\n",
    "\n",
    "def get_arrivals(required_routes):\n",
    "    if type(required_routes[0][0]) == str:\n",
    "        arrivals = list(map(lambda x: x[1], required_routes))\n",
    "    else: \n",
    "        arrivals = list(set(map(lambda x: x[-1][1], required_routes)))\n",
    "    return arrivals\n",
    "\n",
    "def get_product(required_routes, next_chain):\n",
    "    if type(required_routes[0][0]) == str:\n",
    "        required_routes = list(filter(lambda x: x[-2][1] == x[-1][0], product(required_routes, next_chain)))\n",
    "    else: \n",
    "        required_routes = list(filter(lambda x: x[-2][-1][1] == x[-1][0], product(required_routes, next_chain)))\n",
    "    return required_routes\n",
    "\n",
    "def get_routes(origin, final_destination, route_chain, number_flights = 4):\n",
    "    if number_flights == 1:\n",
    "        required_routes = list(set(filter(lambda x: (x[0] in origin) & (x[1] in final_destination), route_chain)))\n",
    "    else:\n",
    "        required_routes = list(set(filter(lambda x: x[0] in origin, route_chain)))\n",
    "        for n in range(1, number_flights):\n",
    "            arrivals = get_arrivals(required_routes)\n",
    "            if n + 1 == number_flights:\n",
    "                next_chain = get_next_chain(arrivals, route_chain, final_destination, True)\n",
    "            else:    \n",
    "                next_chain = get_next_chain(arrivals, route_chain, final_destination)\n",
    "            required_routes = get_product(required_routes, next_chain)           \n",
    "    return required_routes\n",
    "\n",
    "def delete_chains(final_destination, rout):\n",
    "    s = 1\n",
    "    for chain in rout:\n",
    "        if chain[-1] not in final_destination:\n",
    "            s = s + 1\n",
    "        else:\n",
    "            break\n",
    "    rout = rout[:s]\n",
    "    return rout\n",
    "            \n",
    "def flat_route(route):\n",
    "    root = route\n",
    "    result = []\n",
    "    while type(root[-2]) != str:\n",
    "        result.append(root[-1])\n",
    "        root = root[-2]\n",
    "        \n",
    "    result.append(root)\n",
    "    result.reverse()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wishful_routes(route, wishful_point):\n",
    "    result = False\n",
    "    if len(wishful_point) != 0:\n",
    "        for chain in route:\n",
    "            if chain[1] in wishful_point or chain[0] in wishful_point:\n",
    "                result = True\n",
    "        return result\n",
    "    else: return True\n",
    "    \n",
    "    \n",
    "def clean_routes(route):\n",
    "    c = dict(Counter([point for chain in route for point in chain]))\n",
    "    if 3 in list(c.values()): return False\n",
    "    else: return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_routes = get_routes(origin, final_destination, route_chain, number_flights = 1)\n",
    "required_routes = list(map(flat_route, required_routes))\n",
    "required_routes = list(map(lambda x: delete_chains(final_destination, x), required_routes))\n",
    "required_routes = list(filter(lambda x: get_wishful_routes(x, wishful_point), required_routes))\n",
    "required_routes = list(filter(lambda x: clean_routes(x), required_routes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = directions\n",
    "required_routes = list(product(directions, final_destination))\n",
    "\n",
    "required_routes = list(map(lambda x: [x], required_routes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_points = list(set([point for route in required_routes for chain in route for point in chain]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_dates(datetime_start, datetime_end):\n",
    "    delta = timedelta(days = 1)\n",
    "    range_dates = []\n",
    "    date = datetime_start\n",
    "    while date <= datetime_end:\n",
    "        range_dates.append(date)\n",
    "        date = date + delta   \n",
    "    return range_dates\n",
    "\n",
    "def open_json(path):\n",
    "    try:\n",
    "        with open(path, encoding='utf-8', mode = 'r') as file:\n",
    "            json_base = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        json_base = []\n",
    "    return json_base\n",
    "\n",
    "def write_json(path, json_base):\n",
    "    with open(path, encoding='utf-8', mode = 'w') as file:\n",
    "        json.dump(json_base, file)  \n",
    "\n",
    "def write_file(path, json_base, columns): \n",
    "    with open(path, encoding='utf-8', mode = 'a') as file:\n",
    "        for item in json_base:\n",
    "            line_file = []\n",
    "            for key in columns:\n",
    "                line_file.append(str(item[key]))\n",
    "            file.write(\",\".join(line_file) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_destinations(routes, origin):\n",
    "    destination_list = list(filter(lambda x: x['departure_airport_iata'] == origin, routes))\n",
    "    destination_list = list(set(map(lambda x: x['arrival_airport_iata'],destination_list)))\n",
    "    return destination_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_browser_query(path, days = 5):\n",
    "    browser_query = open_json(path)\n",
    "    current_time = datetime.utcnow() - timedelta(days = days)\n",
    "    browser_query = list(filter(lambda x: datetime.strptime(x['timestamp'], \n",
    "                                                            '%Y-%m-%d %H:%M:%S') > current_time, browser_query))  \n",
    "    write_json(path, browser_query)  \n",
    "\n",
    "def check_browser_query(date, origin, destination): \n",
    "    rewrite = True\n",
    "    browser_query = open_json('browser_query.json')\n",
    "    checker = list(filter(lambda x: ((x['date'] == date) & (x['origin'] == origin) & \n",
    "                                     (x['destination'] == destination)), browser_query))    \n",
    "    if len(checker) != 0: rewrite = False          \n",
    "    return rewrite   \n",
    "\n",
    "def add_browser_query(date, origin, destination): \n",
    "    browser_query = open_json('browser_query.json')\n",
    "    browser_query.append({'date':date, 'origin':origin, \n",
    "         'destination':destination, 'timestamp':datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')})\n",
    "    write_json('browser_query.json', browser_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_price_base(path, days = 10):\n",
    "    columns = ['actual', 'depart_date', 'destination', 'distance', 'duration', 'found_at', 'gate', 'number_of_changes',\n",
    "     'origin', 'return_date', 'show_to_affiliates', 'trip_class', 'value']  \n",
    "    if os.path.exists(path):\n",
    "        data = pd.read_csv(path, parse_dates = ['found_at'])\n",
    "        current_time = datetime.utcnow() - timedelta(days = days)\n",
    "        data = data[data['found_at'] > current_time]\n",
    "        data.to_csv(path, index = False)\n",
    "    else:\n",
    "        with open(path, encoding='utf-8', mode = 'a') as file:\n",
    "            file.write(\",\".join(columns) + \"\\n\")\n",
    "        data = pd.read_csv(path, parse_dates = ['found_at'])\n",
    "    return data\n",
    "\n",
    "def check_ticket_price(date, origin, destination, base):\n",
    "    rewrite = base[(base['depart_date'] == date) \n",
    "                     & (base['origin'] == origin) \n",
    "                     & (base['destination'] == destination)].empty      \n",
    "    return rewrite\n",
    "\n",
    "\n",
    "def add_ticket_price(ticket, columns):    \n",
    "    write_file('ticket_base.txt', ticket, columns)\n",
    "    \n",
    "def upload_ticket(token, chain, date, url, ticket_base):\n",
    "    ticket = []\n",
    "    columns = list(ticket_base.columns)\n",
    "    origin, destination = chain\n",
    "    if check_ticket_price(date, origin, destination, ticket_base):\n",
    "        params = {'currency': 'rub', 'show_to_affiliates':'false', 'token' : token, 'one_way':'true',\n",
    "                'origin': origin, 'destination': destination, 'month':date}\n",
    "        response = requests.get(url, params=params)\n",
    "        if 'errors' not in json.loads(response.text)['data']:\n",
    "            ticket = json.loads(response.text)['data']\n",
    "            add_ticket_price(ticket, columns)\n",
    "        else:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_routes(datetime_start, datetime_end, required_routes):\n",
    "    tickets = []\n",
    "    ticket_base = update_price_base('ticket_base.txt')\n",
    "    columns = list(ticket_base.columns)\n",
    "    \n",
    "    update_browser_query('browser_query.json')\n",
    "    stack = []\n",
    "    \n",
    "    parameters = list(product(required_routes, list_dates(datetime_start, datetime_end)))\n",
    "\n",
    "    for route, datetime_object in tqdm(parameters, total=len(parameters), desc='send_query'):\n",
    "        stack.append((route, datetime_object))\n",
    "        month, day = add_zero(datetime_object.month), add_zero(datetime_object.day)\n",
    "        date = datetime_object.strftime('%Y-%m-%d')\n",
    "        for chain in route:\n",
    "            origin, destination = chain\n",
    "\n",
    "            url_for_cash = f'https://www.aviasales.ru/search/{origin}{day}{month}{destination}1'\n",
    "            \n",
    "            if check_ticket_price(date, origin, destination, ticket_base):\n",
    "                upload_ticket(ACCESS_TOKEN, chain, date, url, ticket_base)\n",
    "\n",
    "            if check_browser_query(date, origin, destination) and check_ticket_price(date, origin, destination, ticket_base):\n",
    "                driver.get(url_for_cash)\n",
    "                sleep(time_sleep)\n",
    "                while \"Извините, доступ к поиску\" in driver.page_source:\n",
    "                    check_point = datetime.now()\n",
    "                    print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'sleeping 20 minutes')\n",
    "                    while datetime.now() < check_point + timedelta(minutes = 20):\n",
    "                        if stack:\n",
    "                            route2, datetime_object2 = stack.pop(0)\n",
    "                            date2 = datetime_object2.strftime('%Y-%m-%d')\n",
    "                            for chain2 in route2:\n",
    "                                upload_ticket(ACCESS_TOKEN, chain2, date2, url, ticket_base)\n",
    "                        else: sleep(60)\n",
    "  \n",
    "                    driver.get(url_for_cash)\n",
    "\n",
    "                add_browser_query(date, origin, destination)\n",
    "                \n",
    "    \n",
    "    for route, datetime_object in tqdm(stack, total=len(stack), desc='get_price_from'):\n",
    "        date = datetime_object.strftime('%Y-%m-%d')\n",
    "        for chain in route:\n",
    "            upload_ticket(ACCESS_TOKEN, chain, date, url, ticket_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    # Radius of earth in kilometers is 6371\n",
    "    km = 6371* c\n",
    "    return km\n",
    "\n",
    "\n",
    "def distance(rout, data):\n",
    "    lon1, lat1 = tuple(list(filter(lambda x: (x['city_code'] == rout[0]) \n",
    "                               or (x['code'] == rout[0]), data))[0]['coordinates'].values())\n",
    "    \n",
    "    lon2, lat2 = tuple(list(filter(lambda x: (x['city_code'] == rout[1]) \n",
    "                               or (x['code'] == rout[1]), data))[0]['coordinates'].values())\n",
    "    \n",
    "    km = haversine(lon1, lat1, lon2, lat2)\n",
    "    return km\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance = list(map(lambda x: sum(map(lambda y: distance(y, data),x)), required_routes))\n",
    "# required_routes = [x for _,x in sorted(zip(distance,required_routes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb42e17368849389834c2ccbdc45d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='send_query', max=10200, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-01 23:43:41 sleeping 20 minutes\n",
      "2019-11-02 00:36:17 sleeping 20 minutes\n",
      "2019-11-02 01:10:58 sleeping 20 minutes\n",
      "2019-11-02 01:31:29 sleeping 20 minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b89f5cdca7405780e04b8114c3171b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='get_price_from', max=8533, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tickets_list = []\n",
    "\n",
    "datetime_start = datetime.strptime(date_start, '%Y-%m-%d')\n",
    "datetime_end = datetime.strptime(date_end, '%Y-%m-%d')\n",
    "\n",
    "#destination_list = get_destinations(routes, origin)\n",
    "\n",
    "get_price_routes(datetime_start, datetime_end, required_routes)\n",
    "\n",
    "# for change in range(number_place):\n",
    "#     ponts_list =  list(set(map(lambda x: x['destination'], tickets_list[change])))\n",
    "#     tickets = []\n",
    "#     for point in tqdm(ponts_list, desc=f'for_{change + 1}_point_destination'):\n",
    "#         if change + 1 < number_place: destination_list = get_destinations(routes, point) + final_destination\n",
    "#         else: destination_list = final_destination\n",
    "#         tickets = tickets + get_price_routes(datetime_start, datetime_end, point, destination_list)    \n",
    "            \n",
    "#     tickets_list.append(tickets)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master b80de3c] update jsons\n",
      " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/chylkov/aviasales_parser.git\n",
      "   65c8f83..b80de3c  master -> master\n"
     ]
    }
   ],
   "source": [
    "!git add ticket_base.json\n",
    "!git add browser_query.json\n",
    "!git commit -m \"update jsons\"\n",
    "!git push origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нужно порабатать с кодом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('ticket_base.json')\n",
    "df = df[(df['depart_date'] >= date_start) & (df['depart_date'] <= date_end)]\n",
    "\n",
    "feature = list(df.columns).remove('found_at')\n",
    "\n",
    "df.sort_values(by = 'found_at', ascending=False, inplace=True)\n",
    "df.drop_duplicates(inplace = True, keep = 'first', subset = feature)\n",
    "\n",
    "df.to_csv('routes_price.txt', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Lengths must match to compare",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-223-b3781e5b1fd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                  'duration', 'number_of_changes', 'value']\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf_route\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'origin'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0morigin\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mroute_feature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mchange\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber_place\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other, axis)\u001b[0m\n\u001b[0;32m   1743\u001b[0m             \u001b[1;31m# as it will broadcast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Lengths must match to compare'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1747\u001b[0m             \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Lengths must match to compare"
     ]
    }
   ],
   "source": [
    "route_feature = ['depart_date', 'origin', 'destination', 'distance', \n",
    "                 'duration', 'number_of_changes', 'value']\n",
    "\n",
    "df_route = df[df['origin'] == origin][route_feature]\n",
    "\n",
    "for change in range(number_place):\n",
    "    \n",
    "    if change == 0:\n",
    "        df_route = df_route.merge(df[route_feature], \n",
    "                                           how = 'left', left_on = 'destination', \n",
    "                                           right_on = 'origin', suffixes = ['_from', ''])\n",
    "        \n",
    "        df_route.rename(columns={x:x + '_' + str(change + 1) for x in route_feature}, inplace = True)\n",
    "\n",
    "        df_route = df_route[df_route['depart_date_from'] <= df_route['depart_date_' + str(change + 1)]]\n",
    "    else:\n",
    "        df_route = df_route.merge(df[route_feature], \n",
    "                                           how = 'left', left_on = 'destination_' + str(change), \n",
    "                                           right_on = 'origin')\n",
    "        \n",
    "        df_route.rename(columns={x:x + '_' + str(change + 1) for x in route_feature}, inplace = True)\n",
    "        df_route = df_route[df_route['depart_date_' + str(change)] <= df_route['depart_date_' + str(change+1)]]\n",
    "\n",
    "\n",
    "value_list = list(filter(lambda x: x[:5] == 'value', list(df_route.columns)))\n",
    "df_route['total_value'] =  df_route[value_list].sum(axis = 1)\n",
    "\n",
    "#df_route = df_route[(df_route['depart_date_from'] >= date_start) & (df_route['depart_date_to'] <= date_end)]\n",
    "\n",
    "df_route.sort_values(by = ['total_value', 'depart_date_from'] , inplace = True)\n",
    "\n",
    "df_route = df_route[df_route['destination' + str(change+1)].isin(final_destination)]\n",
    "\n",
    "df_route.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
